{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annacandotti/telerilevamento_2021/blob/main/3DFin_workshop_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3DFin Tutorial: Practical Workshop\n",
        "\n",
        "## *Part I:* Running 3DFin for a dataset collected with a mobile laserscanning system (GeoSlam)\n",
        "\n",
        "In the first tutorial we were dealing with a TLS dataset from a forest stand with comparably simple structure and of high quality. In this exercise we will use a a new dataset which you can access here:\n",
        "\n",
        "[GeoSlam point cloud](https://drive.google.com/file/d/1J9mpSmliG5b563eOKN15nzfD1qqa9pE4/view?usp=sharing)\n",
        "\n",
        "This dataset was collected with a GeoSlam ZEB-Horizon hand-held Mobile Laser Scanning (MLS) system in a forest stand which has a more complex forest structure with more pronounced understorey and also a more complex terrain situation. Furthermore, the dataset is a bit more noisy. MLS systems typically have an increased noise level as compared to the TLS data.\n",
        "\n",
        "A visualization of the dataset after loading it to CloudCompare can be seen in Figure 27.\n",
        "\n",
        "**Figure 27: MLS dataset in CloudCompare.**\n",
        "\n",
        "![Figure 27: MLS dataset in CloudCompare](https://drive.google.com/uc?export=view&id=1nvt6bpBgSWfO1CQcfKyiFLd8cCVv3JK3\n",
        ")"
      ],
      "metadata": {
        "id": "jiAalKul-uNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 1:**\n",
        "\n",
        "As first exercise, **download the dataset** and then run the 3DFin plugin either with the standard settings or slightly adapt the basic parameters based on the visual impression you have from the data as shown in CloudCompare (I selected a minimum height of 1.2 m and a maximum height of 4.2 m and kept the other parameters to their default values)."
      ],
      "metadata": {
        "id": "kTycYOhNcETE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 2:**\n",
        "\n",
        "**Have a close look at the produced data files** and **check** whether you can see **any problems** with the created dataset. Particularly check the following points:\n",
        "\n",
        "- did the workflow detect all tree stems?\n",
        "- are the DBH measurements plausible?\n",
        "- are the height measurements plausible?\n",
        "- is the DTM matching the expected shape of the terrain?\n",
        "\n",
        "**Please only continue reading after you have thoroughly examined the output files in the main visualization window of CloudCompare with respect to the four questions formulated above.**"
      ],
      "metadata": {
        "id": "lsDeyYDp_F_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you have run the 3DFin workflow with the standard settings, it is quite likely that you have found some inconsistencies in the outputs. In the following, we will briefly summarize these inconsistencies and then provide a solution on how to fix them using the Expert settings of the 3DFin workflow.\n",
        "\n",
        "The expert settings rarely have to be touched by the user but there are a few exceptional cases where modifying the settings can help. Particularly, changing the default values with respect to the Height Normalization procedure accomplished with the digital terrain model, can lead to improved results. But let's first have a look at the standard outputs:\n",
        "\n",
        "Let's start with the standard output of the workflow as shown in Figure 28. We can see that there is a quite high number of trees where the DBH estimate is not available because the workflow reported that the estimates are not reliable. At the same time quite a few stem sections are marked in red which indicates potential outliers that do not belong to the tree stem.\n",
        "\n",
        "**Figure 28: Standard outputs of the 3Dfin workflow applied to the MLS dataset.**\n",
        "\n",
        "![Figure 28: Standard outputs of the 3Dfin workflow applied to the MLS dataset ](https://drive.google.com/uc?export=view&id=16_CcRYVulLPlZZg3pOAuVyTKlDUMxZvm)\n",
        "\n",
        "So the results seem to be not as good as we have observed for the first dataset. Let us find out some more about what the reason for this could be.  If we have a look at only the DTM (Fig. 29) we can see that there are some odd-looking parts in the DTM (marked in red in Fig. 29).\n",
        "\n",
        "**Figure 29: DTM visualization.**\n",
        "\n",
        "![Figure 29: DTM visualization](https://drive.google.com/uc?export=view&id=154IDP53X5MAqe9zWy4BVFeDfc_jwXka_)\n",
        "\n",
        "If we also activate the point-cloud we can see that the interpolated DTM in some parts notable deviates from the point cloud (Fig. 30 marked in red). Please be aware that I have adjusted the visualization settings a bit (increased the point size of the DTM and changed the color-scale to \"grey\" for the point cloud) to make these problems a bit better visible.\n",
        "\n",
        "**Figure 30: Mismatch between DTM and point cloud.**\n",
        "\n",
        "![Figure 30: Mismatch between DTM and point cloud](https://drive.google.com/uc?export=view&id=1yulq1GQvrF_pgS0I5VWls_0cnz2n4CIe)\n",
        "\n",
        "When additionally also activating the detected tree stem segments in the stripe (see Tutorial above) we can also see that the workflow missed several trees during the stem detection phase (marked in Figure 31).\n",
        "\n",
        "**Figure 31: Several trees were not detected.**\n",
        "\n",
        "![Figure 31: Several trees were not detected](https://drive.google.com/uc?export=view&id=107-PTIg7iwJsXZZiYgsvoWptjm_1Qnl9)\n",
        "\n",
        "In this specific case, the main reason for these suboptimal results is the quality of the DTM. Since the DTM is not accurately representing the actual shape of the ground, the normalization of the heights leads to wrong point distributions in some parts of the dataset and this affects the workflow negatively. The reason for the low quality of the DTM relates to the comparably steep regions between the individual terrace planes in the plot; that is, the plot has an uneven and complex terrain. The DTM interpolation in this case fails to accurately capture these steep parts because the spatial resolution applied during the DTM interpolation is too coarse.\n",
        "\n",
        "Note that this does not happen only because of the steepness of the terrain, but also because of the heterogeneity of the terrain and the abundance of sudden changes in the slopes. The DTM generation in 3DFin is based on the Cloth Simulation Filter. In that algorithm, the cloth resolution is a key parameter. Please, refer to Zhang et al. (2016) for further details.\n",
        "\n",
        "*Zhang W, Qi J, Wan P, Wang H, Xie D, Wang X, Yan G. An Easy-to-Use Airborne LiDAR Data Filtering Method Based on Cloth Simulation. Remote Sensing. 2016; 8(6):501.*\n",
        "\n",
        "We will now try to fix this by changing the so called \"cloth-size\" in the section \"Height Normalization\" in the expert settings of 3DFin.\n",
        "\n",
        "For this, we restart the 3DFin workflow and use the exactly same basic settings as in the run before but before we press the \"compute\" button, we **switch to the \"Expert\"-tab** of the 3DFin user interface and **change the \"Cloth resolution\" to 0.4 m** (marked in red in Fig. 32) and then press **\"Compute\".**\n",
        "\n",
        "**Figure 32: Change the cloth resolution.**\n",
        "\n",
        "![Figure 32: Change the cloth resolution.](https://drive.google.com/uc?export=view&id=1SmCphPsMtk7JfHCgo3-IwaXhu0chlFs-)\n",
        "\n",
        "The DTM obtained with these new settings looks notably better than the outputs of the first run. In a transect view (Fig. 33) it is nicely visible that the terrain model now smoothly follows the shape of the ground shown in the original point cloud.\n",
        "\n",
        "**Figure 33: The DTM now matches the point cloud nicely.**\n",
        "\n",
        "![Figure 33: The DTM now matches the point cloud nicely.](https://drive.google.com/uc?export=view&id=14hh53831d2_EPN4oa30FxeR1lFgi19lC)\n",
        "\n",
        "We furthermore can see in the console outputs as well as in the created tabular output data that the number of detected trees has increased from 57 to 70. A visual screening confirms that all trees have now been detected.  (Fig. 34).\n",
        "\n",
        "**Figure 34: Stems are now well detected.**\n",
        "\n",
        "![Figure 34: Stems are now well detected.](https://drive.google.com/uc?export=view&id=1rNSPlsIvxLsGTi5FYG6t5_cfTDbuYLSw)\n",
        "\n",
        "We can also see that in the standard outputs of the workflow or when activating the \"tree locator\" layer in the DB tree window of CloudCompare that most of the trees now also have an estimate of the DBH.\n",
        "\n",
        "![Figure 35: Standard output view of 3DFin after adjusting the cloth setting.](https://drive.google.com/uc?export=view&id=1097uoPJ-Wtvk8k-s0lIH2VvxC8YTGrC9)\n",
        "\n",
        "**Figure 35: Standard output view of 3DFin after adjusting the cloth setting.**\n",
        "\n",
        "With this exercise you have learned one way of adjusting the 3D workflow in case the results with the standard settings are not satisfactory. Checking the quality of the DTM is generally recommended at is one of the few variables that can affect the workflow negatively.\n",
        "\n",
        "If you fail to derive a high quality DTM using the algorithm integrated into the 3DFin workflow, but have managed to calculate a high-quality DTM in another software-environment (e.g., LAStools or FUSION), you can also provide an already normalized point-cloud file to 3DFin.\n",
        "\n",
        "In this case you would **uncheck the \"Normalize point cloud\" box** in the Basic-tab of the 3DFin user interface. By unchecking the box, the drop-down menu \"Normalized Height Field Name\" will be activated and you will have to **select the attribute name** of the data column that includes the normalized height values of the point-cloud. After this, you can run the workflow as learned before.\n",
        "\n",
        "This option can also be used to reduce processing time: In case you have already run the 3DFin workflow successfully one time and the quality of the DTM was good, you can re-use the point-cloud created by the 3DFin workflow for this purposes. Each point cloud created by the 3DFin workflow contains a normalized height field and can hence be directly put into the workflow again without the need to normalize the point cloud again. One situation in which you could be interested in this is if you want to for example check how the outputs of the workflow is influenced by changing some of the settings in the \"Advanced\"-tab of the 3DFin user interface.\n",
        "\n",
        "With this final tip, we have reached the end of the tutorial with respect to the data processing in CloudCompare. In Exercise II we will learn how we can process the outputs of the 3DFin workflow to higher-level information products. More concretely, we will derive volume and then biomass estimates for the trees trunks identified from the first dataset."
      ],
      "metadata": {
        "id": "XDTAKwWJ_4t7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II - Calculating stem volumes and biomass for individual trees based on the 3Dfin outputs\n",
        "\n",
        "In the following you will find a code example for R with which you can calculate individual tree stem volumes from the 3DFin outputs. The code is based on the calculation of volumes of the frustums that can defined by the stem sections diameters identified by the 3DFin workflow and the height intervals between the identified stem section.\n",
        "\n",
        "In the code provided below, the outputs of the 3DFin workflow created during the first part of the Tutorial are processed. The code is commented with quite a lot of details and should be more or less self-explanatory.  \n",
        "\n",
        "To calculate the volume of the Frustrum we use the following equation:\n",
        "\n",
        "**Equation 1: Frustum volume.**\n",
        "\n",
        "![Equation 1: Frustum volume](https://drive.google.com/uc?export=view&id=13xviQ6NdU3lY8HnYFdd-cPkJ59cRMpq1)\n",
        "\n",
        "**Figure 36: Frustum. Figure from Wikipedia: https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/01-Kegelstumpf-Definition-H%C3%B6he.svg/300px-01-Kegelstumpf-Definition-H%C3%B6he.svg.png**\n",
        "![Figure 36: Frustum - Figure from Wikipedia: https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/01-Kegelstumpf-Definition-H%C3%B6he.svg/300px-01-Kegelstumpf-Definition-H%C3%B6he.svg.png ](https://drive.google.com/uc?export=view&id=11e9PHV0dYPWvdwb1SSF7DBcEGPsUPKvk\n",
        ")\n",
        "\n",
        "This equation is also defined at the beginning of the R code provided below. After excluding tree stem section that either have 0 diameters or where identified to be of low quality, the code iterates through the stem sections of each individual tree, one tree after another."
      ],
      "metadata": {
        "id": "DKneOjkXBCyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "# load input files\n",
        "####################\n",
        "\n",
        "# load heights of stem sections (these are the same for each tree)\n",
        "hts <- read.table(\"https://drive.google.com/uc?export=view&id=1HCqdACno5fFbdoQi46Q1XVLS8YUHM6-2\", sep=\" \")\n",
        "# load diameters of stem sections\n",
        "dm <- read.table(\"https://drive.google.com/uc?export=view&id=1_SeuBZSNuk0yKaTOwbCb-RxCPC36bGJa\", sep=\" \")\n",
        "# load quality indicator\n",
        "qu <- read.table(\"https://drive.google.com/uc?export=view&id=1MnLmQvXjnw8jheFOIej-mPdZvzG8vBnO\", sep=\" \")\n",
        "# load top height trees\n",
        "tht <- read.table(\"https://drive.google.com/uc?export=view&id=1DSNZeq4eI-IdUUqVvdW29SegBiNwANMS\", sep=\" \")\n",
        "tht_trees <- tht$V1"
      ],
      "metadata": {
        "id": "5LyBOkCClIGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################################\n",
        "# define function to calculate volume of a frustrum #\n",
        "#####################################################\n",
        "get_vol_fr <- function(h, Rbase, Rceil) {1/3*pi*(Rbase^2+(Rbase*Rceil)+Rceil^2)*h}"
      ],
      "metadata": {
        "id": "Angj3YhFSKhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# calculate volume of all trees #\n",
        "#################################\n",
        "\n",
        "# create empty list to store results\n",
        "tree_volume_list <- list()\n",
        "\n",
        "#####################################\n",
        "# first loop iterates through trees #\n",
        "#####################################\n",
        "\n",
        "for (t in 1:nrow(dm)){\n",
        "  # take diameters of t-th tree\n",
        "  dmt <- dm[t,]\n",
        "  # take quality of t-th tree\n",
        "  qut <- qu[t,]\n",
        "\n",
        "  # merge diameters, quality and height information\n",
        "  dmt_ht <- rbind(dmt, hts, qut)\n",
        "\n",
        "  # drop stem sections 0 diameters and quality != 0\n",
        "  dmt_clean <- dmt_ht[,(dmt_ht[1,]!=0)]\n",
        "  dmt_clean2 <- dmt_clean[,(dmt_clean[3,]==0)]\n",
        "\n",
        "  # create empty list to save frustrum volumes for current tree\n",
        "  vollist <- list()\n",
        "\n",
        "  ####################\n",
        "  # second loop iterates through stem sections of current tree\n",
        "  ####################\n",
        "\n",
        "  for (i in 1:(ncol(dmt_clean2)-1)){\n",
        "\n",
        "    # create second iterator variable to get height of next section\n",
        "    i2=i+1\n",
        "\n",
        "    # calculate height of segment by subtracting height of current\n",
        "    # stem section from height of subsequent height section\n",
        "    ht_fr = as.numeric(dmt_clean2[2,i2]-dmt_clean2[2,i])\n",
        "    # get radius of current height section [multiply diameter times 0.5]\n",
        "    Rbase = dmt_clean2[1,i]*0.5\n",
        "    # get radius of next height section\n",
        "    Rceil = dmt_clean2[1,i2]*0.5\n",
        "\n",
        "    # insert height of segment and radius of base and ceiling section\n",
        "    # in volume formula\n",
        "    vol_temp <- get_vol_fr(ht_fr, Rbase, Rceil)\n",
        "    # save volume of current frstrum into list\n",
        "    vollist[[i]] <- vol_temp\n",
        "    }\n",
        "\n",
        "  # calculate volume of last stem section to tree top\n",
        "  voltop <- pi*(dmt_clean2[1,i2]*0.5)^2*(tht_trees[t]-dmt_clean2[2,i2])\n",
        "\n",
        "  # calculate total volume of all frustrums plus top cone\n",
        "  tot_vol <- do.call(sum, vollist) + voltop\n",
        "\n",
        "  # store total volume of tree to list\n",
        "  tree_volume_list[[t]] <- tot_vol\n",
        "  }"
      ],
      "metadata": {
        "id": "FGVXr-yTQ2Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end of the code, we will have a tree volume estimation for each tree stem identified in the 3DFin work-flow."
      ],
      "metadata": {
        "id": "e2-2v801RsUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check single tree volumes\n",
        "tree_volume_list"
      ],
      "metadata": {
        "id": "Z5eCyHBTRU5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check volume of all trees combined\n",
        "vol_stand <- do.call(sum, tree_volume_list)\n",
        "vol_stand"
      ],
      "metadata": {
        "id": "j7ao-5kIRWap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "645fcd6a-6e00-4e7d-cc6c-03b492f48e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "10.8073561767951"
            ],
            "text/markdown": "10.8073561767951",
            "text/latex": "10.8073561767951",
            "text/plain": [
              "[1] 10.80736"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Part III:* Analysis of the results from 3DFin. Estimating the accuracy of the metrics.\n",
        "\n",
        "In this part of the workshop we will use R to analyse how good/bad are the obtained results. For this, we first need to import in R the datasets that we will employ. These are the reference datasets, with manually measurements of tree location, DBH and TH, and the results obtained by 3DFin."
      ],
      "metadata": {
        "id": "l0pUpT2HAVTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import the data in R**\n",
        "\n",
        "For convenience, a copy of the reference dataset and a copy of the 3DFin results dataset have been uploaded to a Google Drive shared folder. A R file containing functions to analyse the results has been uploaded as well. In the following code blocks, we will load the required libraries to import and manipulate the data and the R file.\n",
        "\n",
        "Three libraries will be used:\n",
        "- `readxl` Library to read xlsx files. It does not allow to import directly from a link.\n",
        "- `googledrive` Library that allows readxl to open a request to Google Drive.\n",
        "- `dplyr` Library to manipulate dataframes."
      ],
      "metadata": {
        "id": "q9mYN9dqcqNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "library(readxl)\n",
        "library(googledrive)\n",
        "library(dplyr)"
      ],
      "metadata": {
        "id": "vJse5PxhjYjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the R file the functions to analyse the results\n",
        "source(\"https://drive.google.com/uc?export=view&id=1_3PYrjqUfGle6FgzCQxgTaYYRhoa79fZ\")"
      ],
      "metadata": {
        "id": "vvTkDgrbrTnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reference data\n",
        "\n",
        "The following code blocks are used to read the reference dataset.\n",
        "\n",
        "readxl needs permission from Google Drive to read xlsl files from a Drive link. For this reason, running the first cell will prompt a message asking the following:\n",
        "\n",
        "**Is it OK to cache OAuth access credentials in the folder ~/.cache/gargle\n",
        "between R sessions?**\n",
        "\n",
        "Simply type '1' in the text entry box and a link to generate an access token will be provided. Then, click the link and follow the instructions on the new website. *You need to grant Tidyverse API momentaneous access to your account, but that's ok*."
      ],
      "metadata": {
        "id": "58DxbzCXy7qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl <- drive_download(\n",
        " as_id(\"https://docs.google.com/spreadsheets/d/1kGDWHsVizfoXp3Mrd0roOUC0v-T7DqOa/edit#gid=659133055\"),\n",
        "  path = 'reference.xlsx',\n",
        "  overwrite = TRUE,\n",
        "  type = \"xlsx\")"
      ],
      "metadata": {
        "id": "aGEMcMytmhpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971ce1a0-7010-441e-cb3f-a3fd8d92ec81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m\u001b[22mIs it OK to cache OAuth access credentials in the folder \u001b[34m~/.cache/gargle\u001b[39m\n",
            "between R sessions?\n",
            "\u001b[1m1\u001b[22m: Yes\n",
            "\u001b[1m2\u001b[22m: No\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selection: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Please point your browser to the following url: \n",
            "\n",
            "https://accounts.google.com/o/oauth2/v2/auth?client_id=603366585132-frjlouoa3s2ono25d2l9ukvhlsrlnr7k.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&redirect_uri=https%3A%2F%2Fwww.tidyverse.org%2Fgoogle-callback%2F&response_type=code&state=c2de805fdb784c172fb222ee41df45be&access_type=offline&prompt=consent\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter authorization code: eyJjb2RlIjoiNC8wQVpFT3ZoWHlkRGwzazNyYTYyNk5qWHZJdVR3Tk1NUHlyWnR3UTFDLVhNd2xrMktSNndfUzc0MVBUaWM2NVFVT2Nrb19lQSIsInN0YXRlIjoiYzJkZTgwNWZkYjc4NGMxNzJmYjIyMmVlNDFkZjQ1YmUifQ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m!\u001b[39m Ignoring `type`. Only consulted for native Google file types.\n",
            "\n",
            "  MIME type of `file`: \u001b[32mmime_type\u001b[39m.\n",
            "\n",
            "File downloaded:\n",
            "\n",
            "• \u001b[36mTLS_06_reference.xlsx\u001b[39m \u001b[90m<id: 1kGDWHsVizfoXp3Mrd0roOUC0v-T7DqOa>\u001b[39m\n",
            "\n",
            "Saved locally as:\n",
            "\n",
            "• \u001b[34mreference.xlsx\u001b[39m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K9lxCIwdpzc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "c1a04708-3ad9-4015-ed22-5f3db8d19d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m\u001b[22mNew names:\n",
            "\u001b[36m•\u001b[39m `` -> `...1`\n",
            "\u001b[36m•\u001b[39m `` -> `...2`\n",
            "\u001b[36m•\u001b[39m `` -> `...3`\n",
            "\u001b[36m•\u001b[39m `` -> `...4`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 4</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>ID</th><th scope=col>X</th><th scope=col>Y</th><th scope=col>DBH</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>1</td><td>-2.175</td><td> 6.406</td><td>39.20</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>2</td><td> 9.622</td><td>10.858</td><td>33.65</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>3</td><td>11.960</td><td> 8.568</td><td>41.05</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>4</td><td> 2.866</td><td> 3.663</td><td>35.90</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>5</td><td> 8.542</td><td> 4.278</td><td>42.15</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>6</td><td> 4.379</td><td>-3.058</td><td>45.20</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 4\n\n| <!--/--> | ID &lt;dbl&gt; | X &lt;dbl&gt; | Y &lt;dbl&gt; | DBH &lt;dbl&gt; |\n|---|---|---|---|---|\n| 1 | 1 | -2.175 |  6.406 | 39.20 |\n| 2 | 2 |  9.622 | 10.858 | 33.65 |\n| 3 | 3 | 11.960 |  8.568 | 41.05 |\n| 4 | 4 |  2.866 |  3.663 | 35.90 |\n| 5 | 5 |  8.542 |  4.278 | 42.15 |\n| 6 | 6 |  4.379 | -3.058 | 45.20 |\n\n",
            "text/latex": "A data.frame: 6 × 4\n\\begin{tabular}{r|llll}\n  & ID & X & Y & DBH\\\\\n  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t1 & 1 & -2.175 &  6.406 & 39.20\\\\\n\t2 & 2 &  9.622 & 10.858 & 33.65\\\\\n\t3 & 3 & 11.960 &  8.568 & 41.05\\\\\n\t4 & 4 &  2.866 &  3.663 & 35.90\\\\\n\t5 & 5 &  8.542 &  4.278 & 42.15\\\\\n\t6 & 6 &  4.379 & -3.058 & 45.20\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  ID X      Y      DBH  \n",
              "1 1  -2.175  6.406 39.20\n",
              "2 2   9.622 10.858 33.65\n",
              "3 3  11.960  8.568 41.05\n",
              "4 4   2.866  3.663 35.90\n",
              "5 5   8.542  4.278 42.15\n",
              "6 6   4.379 -3.058 45.20"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "filename <- \"reference.xlsx\"\n",
        "\n",
        "sheet_name <- \"reference_data\"\n",
        "start_row <- 2\n",
        "start_col <- 1\n",
        "col_names <- c(\"ID\", \"X\", \"Y\", \"DBH\")\n",
        "reference <- read_table_from_xlsx(filename, sheet_name, start_row, start_col, col_names)\n",
        "head(reference)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3DFin outputs\n",
        "\n",
        "The same code allows us to read the 3DFin results."
      ],
      "metadata": {
        "id": "V3h31YJzzLFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl <- drive_download(\n",
        " as_id(\"https://docs.google.com/spreadsheets/d/1p_ukX_RKYBq2J-XIEq9qRwowEU-BZlII/edit#gid=798913215\"),\n",
        "  path = 'detected.xlsx',\n",
        "  overwrite = TRUE,\n",
        "  type = \"xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFFiYHyjzHgi",
        "outputId": "493664b9-3ea0-45d0-b127-b03ab48f3c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m!\u001b[39m Ignoring `type`. Only consulted for native Google file types.\n",
            "\n",
            "  MIME type of `file`: \u001b[32mmime_type\u001b[39m.\n",
            "\n",
            "File downloaded:\n",
            "\n",
            "• \u001b[36mTLS_06.xlsx\u001b[39m \u001b[90m<id: 1p_ukX_RKYBq2J-XIEq9qRwowEU-BZlII>\u001b[39m\n",
            "\n",
            "Saved locally as:\n",
            "\n",
            "• \u001b[34mdetected.xlsx\u001b[39m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmjPxGtlzJYD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "6be1ea18-5d68-4582-8e15-22175c6ec43b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m\u001b[22mNew names:\n",
            "\u001b[36m•\u001b[39m `` -> `...1`\n",
            "\u001b[36m•\u001b[39m `` -> `...2`\n",
            "\u001b[36m•\u001b[39m `` -> `...3`\n",
            "\u001b[36m•\u001b[39m `` -> `...4`\n",
            "\u001b[36m•\u001b[39m `` -> `...5`\n",
            "\u001b[36m•\u001b[39m `` -> `...6`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 4</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>TH</th><th scope=col>DBH</th><th scope=col>X</th><th scope=col>Y</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>31.44164</td><td>0.4983329</td><td>-10.420983</td><td> 4.348686</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>30.08048</td><td>0.3461810</td><td> -5.747097</td><td>10.549545</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>32.16939</td><td>0.3949149</td><td> -6.812729</td><td>-1.486378</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>32.60015</td><td>0.3753893</td><td> -6.055838</td><td> 2.856322</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>31.58934</td><td>0.3927585</td><td> -2.018460</td><td> 6.504026</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>32.20909</td><td>0.5363355</td><td> -2.461813</td><td>-1.162483</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 4\n\n| <!--/--> | TH &lt;dbl&gt; | DBH &lt;dbl&gt; | X &lt;dbl&gt; | Y &lt;dbl&gt; |\n|---|---|---|---|---|\n| 1 | 31.44164 | 0.4983329 | -10.420983 |  4.348686 |\n| 2 | 30.08048 | 0.3461810 |  -5.747097 | 10.549545 |\n| 3 | 32.16939 | 0.3949149 |  -6.812729 | -1.486378 |\n| 4 | 32.60015 | 0.3753893 |  -6.055838 |  2.856322 |\n| 5 | 31.58934 | 0.3927585 |  -2.018460 |  6.504026 |\n| 6 | 32.20909 | 0.5363355 |  -2.461813 | -1.162483 |\n\n",
            "text/latex": "A data.frame: 6 × 4\n\\begin{tabular}{r|llll}\n  & TH & DBH & X & Y\\\\\n  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t1 & 31.44164 & 0.4983329 & -10.420983 &  4.348686\\\\\n\t2 & 30.08048 & 0.3461810 &  -5.747097 & 10.549545\\\\\n\t3 & 32.16939 & 0.3949149 &  -6.812729 & -1.486378\\\\\n\t4 & 32.60015 & 0.3753893 &  -6.055838 &  2.856322\\\\\n\t5 & 31.58934 & 0.3927585 &  -2.018460 &  6.504026\\\\\n\t6 & 32.20909 & 0.5363355 &  -2.461813 & -1.162483\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  TH       DBH       X          Y        \n",
              "1 31.44164 0.4983329 -10.420983  4.348686\n",
              "2 30.08048 0.3461810  -5.747097 10.549545\n",
              "3 32.16939 0.3949149  -6.812729 -1.486378\n",
              "4 32.60015 0.3753893  -6.055838  2.856322\n",
              "5 31.58934 0.3927585  -2.018460  6.504026\n",
              "6 32.20909 0.5363355  -2.461813 -1.162483"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "filename <- \"detected.xlsx\"\n",
        "\n",
        "sheet_name <- \"Plot Metrics\"\n",
        "start_row <- 4\n",
        "start_col <- 3\n",
        "col_names <- c(\"TH\", \"DBH\", \"X\", \"Y\")\n",
        "detected <- read_table_from_xlsx(filename, sheet_name, start_row, start_col, col_names)\n",
        "head(detected)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 3:** Analyse the results obtained with 3DFin\n",
        "### **3.1** *Match detected trees and reference trees*\n",
        "\n",
        "An important step to validate the results of any automatic forest inventory procedure is to match the trees that have been detected by the algorithm to the reference trees in the original forest plot (if there is any match). This assumes that the trees have been manually located and measured in the forest.\n",
        "\n",
        "To match the reference trees and the detected trees by 3DFin in a convenient way, `match_results` function is provided. It matches the detected trees to the reference based on their distance to them. The output of the function is a data.frame with as many rows as there are detected trees and 3 columns: ID, X, Y. If a tree has been matched, the ID is the one corresponding to the reference tree. If a tree has no match, the ID is 9999.\n",
        "\n",
        "The following code chunk uses this function to match the trees, with a $0.15$ $\\text{m}$ threshold."
      ],
      "metadata": {
        "id": "KzSa_iA4z3iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference_xy <- reference[, c(2, 3)]\n",
        "detected_xy <- detected[, c(3, 4)]\n",
        "\n",
        "detected_with_id <- match_results(reference_xy, detected_xy, threshold = 0.30)\n",
        "head(detected_with_id)"
      ],
      "metadata": {
        "id": "giybLTmP0Cqd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "efcb2f4b-4265-4bab-a9f2-9cb889eed7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 4</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>ID</th><th scope=col>X</th><th scope=col>Y</th><th scope=col>Distance</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>19</td><td>-10.420983</td><td> 4.348686</td><td>0.2436945</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>20</td><td> -5.747097</td><td>10.549545</td><td>0.2132177</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>17</td><td> -6.812729</td><td>-1.486378</td><td>0.1887297</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>18</td><td> -6.055838</td><td> 2.856322</td><td>0.2832351</td></tr>\n",
              "\t<tr><th scope=row>5</th><td> 1</td><td> -2.018460</td><td> 6.504026</td><td>0.1846990</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>13</td><td> -2.461813</td><td>-1.162483</td><td>0.1293370</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 4\n\n| <!--/--> | ID &lt;dbl&gt; | X &lt;dbl&gt; | Y &lt;dbl&gt; | Distance &lt;dbl&gt; |\n|---|---|---|---|---|\n| 1 | 19 | -10.420983 |  4.348686 | 0.2436945 |\n| 2 | 20 |  -5.747097 | 10.549545 | 0.2132177 |\n| 3 | 17 |  -6.812729 | -1.486378 | 0.1887297 |\n| 4 | 18 |  -6.055838 |  2.856322 | 0.2832351 |\n| 5 |  1 |  -2.018460 |  6.504026 | 0.1846990 |\n| 6 | 13 |  -2.461813 | -1.162483 | 0.1293370 |\n\n",
            "text/latex": "A data.frame: 6 × 4\n\\begin{tabular}{r|llll}\n  & ID & X & Y & Distance\\\\\n  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t1 & 19 & -10.420983 &  4.348686 & 0.2436945\\\\\n\t2 & 20 &  -5.747097 & 10.549545 & 0.2132177\\\\\n\t3 & 17 &  -6.812729 & -1.486378 & 0.1887297\\\\\n\t4 & 18 &  -6.055838 &  2.856322 & 0.2832351\\\\\n\t5 &  1 &  -2.018460 &  6.504026 & 0.1846990\\\\\n\t6 & 13 &  -2.461813 & -1.162483 & 0.1293370\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  ID X          Y         Distance \n",
              "1 19 -10.420983  4.348686 0.2436945\n",
              "2 20  -5.747097 10.549545 0.2132177\n",
              "3 17  -6.812729 -1.486378 0.1887297\n",
              "4 18  -6.055838  2.856322 0.2832351\n",
              "5  1  -2.018460  6.504026 0.1846990\n",
              "6 13  -2.461813 -1.162483 0.1293370"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2** *Compute Completeness and Correctness*"
      ],
      "metadata": {
        "id": "w6h24Bv53u-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A first useful measurement is to calculate what percentage of the reference trees have been matched (*Completeness*) and what percentage of all detected trees are actual reference trees (*Correctness*). To proceed, we need to prepare the data to be analysed.\n",
        "\n",
        "In the code chunk below, we add the DBH and TH information to the `detected_with_id` dataframe, and then we join the reference dataset and the detected trees to keep only the actual matches."
      ],
      "metadata": {
        "id": "3vjsMhEZ33vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detected_with_id <- detected_with_id %>%\n",
        "  mutate(DBH = detected$DBH)\n",
        "\n",
        "matched_trees <- reference %>%\n",
        "  left_join(detected_with_id, by = \"ID\")\n",
        "\n",
        "col_names <- c(\"ID\", \"true_X\", \"true_Y\", \"true_DBH\", \"X\", \"Y\", \"distance\", \"DBH\")\n",
        "names(matched_trees) <- col_names\n",
        "head(matched_trees)"
      ],
      "metadata": {
        "id": "nxKl2RgH0_2l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "76658ceb-7d1d-4b24-8a10-9d260515f896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 8</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>ID</th><th scope=col>true_X</th><th scope=col>true_Y</th><th scope=col>true_DBH</th><th scope=col>X</th><th scope=col>Y</th><th scope=col>distance</th><th scope=col>DBH</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>1</td><td>-2.175</td><td> 6.406</td><td>39.20</td><td>-2.018460</td><td> 6.504026</td><td>0.18469898</td><td>0.3927585</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>2</td><td> 9.622</td><td>10.858</td><td>33.65</td><td> 9.731618</td><td>10.861650</td><td>0.10967888</td><td>0.3377254</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>3</td><td>11.960</td><td> 8.568</td><td>41.05</td><td>11.929498</td><td> 8.529686</td><td>0.04897293</td><td>0.4177071</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>4</td><td> 2.866</td><td> 3.663</td><td>35.90</td><td> 2.841383</td><td> 3.687945</td><td>0.03504646</td><td>0.3518731</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>5</td><td> 8.542</td><td> 4.278</td><td>42.15</td><td> 8.631143</td><td> 4.267186</td><td>0.08979683</td><td>0.4187755</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>6</td><td> 4.379</td><td>-3.058</td><td>45.20</td><td> 4.326658</td><td>-2.933516</td><td>0.13504064</td><td>0.4673475</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 8\n\n| <!--/--> | ID &lt;dbl&gt; | true_X &lt;dbl&gt; | true_Y &lt;dbl&gt; | true_DBH &lt;dbl&gt; | X &lt;dbl&gt; | Y &lt;dbl&gt; | distance &lt;dbl&gt; | DBH &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|\n| 1 | 1 | -2.175 |  6.406 | 39.20 | -2.018460 |  6.504026 | 0.18469898 | 0.3927585 |\n| 2 | 2 |  9.622 | 10.858 | 33.65 |  9.731618 | 10.861650 | 0.10967888 | 0.3377254 |\n| 3 | 3 | 11.960 |  8.568 | 41.05 | 11.929498 |  8.529686 | 0.04897293 | 0.4177071 |\n| 4 | 4 |  2.866 |  3.663 | 35.90 |  2.841383 |  3.687945 | 0.03504646 | 0.3518731 |\n| 5 | 5 |  8.542 |  4.278 | 42.15 |  8.631143 |  4.267186 | 0.08979683 | 0.4187755 |\n| 6 | 6 |  4.379 | -3.058 | 45.20 |  4.326658 | -2.933516 | 0.13504064 | 0.4673475 |\n\n",
            "text/latex": "A data.frame: 6 × 8\n\\begin{tabular}{r|llllllll}\n  & ID & true\\_X & true\\_Y & true\\_DBH & X & Y & distance & DBH\\\\\n  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t1 & 1 & -2.175 &  6.406 & 39.20 & -2.018460 &  6.504026 & 0.18469898 & 0.3927585\\\\\n\t2 & 2 &  9.622 & 10.858 & 33.65 &  9.731618 & 10.861650 & 0.10967888 & 0.3377254\\\\\n\t3 & 3 & 11.960 &  8.568 & 41.05 & 11.929498 &  8.529686 & 0.04897293 & 0.4177071\\\\\n\t4 & 4 &  2.866 &  3.663 & 35.90 &  2.841383 &  3.687945 & 0.03504646 & 0.3518731\\\\\n\t5 & 5 &  8.542 &  4.278 & 42.15 &  8.631143 &  4.267186 & 0.08979683 & 0.4187755\\\\\n\t6 & 6 &  4.379 & -3.058 & 45.20 &  4.326658 & -2.933516 & 0.13504064 & 0.4673475\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  ID true_X true_Y true_DBH X         Y         distance   DBH      \n",
              "1 1  -2.175  6.406 39.20    -2.018460  6.504026 0.18469898 0.3927585\n",
              "2 2   9.622 10.858 33.65     9.731618 10.861650 0.10967888 0.3377254\n",
              "3 3  11.960  8.568 41.05    11.929498  8.529686 0.04897293 0.4177071\n",
              "4 4   2.866  3.663 35.90     2.841383  3.687945 0.03504646 0.3518731\n",
              "5 5   8.542  4.278 42.15     8.631143  4.267186 0.08979683 0.4187755\n",
              "6 6   4.379 -3.058 45.20     4.326658 -2.933516 0.13504064 0.4673475"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the data is ready, we can compute Completeness and Correctness using the following formulas:\n",
        "\n",
        "$\\text{Completeness} = \\frac{n_{match}}{n_{ref}}$\n",
        "\n",
        "$\\text{Correctness} = \\frac{n_{match}}{n_{det}}$\n",
        "\n",
        "Where $n_{match}$ is the number of matched trees, $n_{ref}$ is the number of reference trees and $n_{det}$ is the number of detected trees."
      ],
      "metadata": {
        "id": "vWJ3eCUT7azw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_match <- nrow(matched_trees)\n",
        "n_ref <- nrow(reference)\n",
        "n_det <- nrow(detected)\n",
        "\n",
        "completeness <- n_match / n_ref * 100; print(paste(\"completeness =\", completeness, \"%\"))\n",
        "correctness <- n_match / n_det * 100; print(paste(\"correctness =\", correctness, \"%\"))"
      ],
      "metadata": {
        "id": "thGiypZu627C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce51fe7f-fc2b-4133-84ee-6055a483aa0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"completeness = 100 %\"\n",
            "[1] \"correctness = 100 %\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3** *Analyse the Diameter at Breast Height (DBH) estimations*\n",
        "\n",
        "To analyse the DBH estimated by 3DFin, we will compute the *Root Mean Squared Error (RMSE)* and the *Bias* of the estimations.\n",
        "\n",
        "The RMSE gives us an idea of how much error has been incorporated, in average, into the measurements. It is computed using the following formula:\n",
        "\n",
        "$\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$,\n",
        "\n",
        "where $n$ is the number of observations or data points $y_i$ represents the observed or actual value for the $i$th data point (the true DBH of the reference tree) and $\\hat{y}_i$ represents the predicted or estimated value for the $i$th data point (the computed DBH value for the detected tree).\n",
        "\n",
        "An useful, complementary metric is to express the RMSE as a percentage of the average reference value (in this case, the reference DBH), which can be computed as follows:\n",
        "\n",
        "$\\text{RMSE (%)}=\\frac{\\text{RMSE}}{\\bar{y}} * 100$,\n",
        "\n",
        "where:\n",
        "\n",
        "$\\bar{y}=\\frac{1}{n_{match}}\\sum_{i=1}^{n}(y_i)$."
      ],
      "metadata": {
        "id": "9nKKx8jg7_L-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bias, on the other hand, refers to the systematic error or deviation of an estimator from the true value of a population parameter. It is a measure of the tendency of an estimator (in this case, 3DFin's algorithm) to consistently overestimate or underestimate the parameter it is trying to estimate (in this case, the true DBH). It can be computed using the following formula:\n",
        "\n",
        "$\\text{Bias} = {\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)}$.\n",
        "\n",
        "Similarly to RMSE, we can express bias as a percentage to asses how small/large that value is, relative to the average reference DBH:\n",
        "\n",
        "$\\text{Bias (%)}=\\frac{\\text{Bias}}{\\bar{y}} * 100$."
      ],
      "metadata": {
        "id": "z8YcYy-s9yb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `acc_results` function in the R file allows to directly compute these 4 metrics. The following code chunk implements it:"
      ],
      "metadata": {
        "id": "PXuouP97-l0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter trees with diameter = 0 (trees where DBH did not pass quality checks)\n",
        "# And transform true_DBH to metres (it's in centimetres right now)\n",
        "matched_trees_filtered <- matched_trees %>%\n",
        "  filter(DBH > 0) %>%\n",
        "  mutate(true_DBH = true_DBH / 100)\n",
        "\n",
        "dbh_results <- compute_acc_results(matched_trees_filtered[, 4], matched_trees_filtered[, 8])\n",
        "dbh_results"
      ],
      "metadata": {
        "id": "kiQ1tXwo8LRi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "0406e04a-29db-4c03-af69-b9d8c1c6b3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 1 × 4</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>RMSE</th><th scope=col>Bias</th><th scope=col>RMSE_pct</th><th scope=col>Bias_pct</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>0.0067</td><td>0.0016</td><td>1.6422</td><td>0.3808</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 1 × 4\n\n| RMSE &lt;dbl&gt; | Bias &lt;dbl&gt; | RMSE_pct &lt;dbl&gt; | Bias_pct &lt;dbl&gt; |\n|---|---|---|---|\n| 0.0067 | 0.0016 | 1.6422 | 0.3808 |\n\n",
            "text/latex": "A data.frame: 1 × 4\n\\begin{tabular}{llll}\n RMSE & Bias & RMSE\\_pct & Bias\\_pct\\\\\n <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t 0.0067 & 0.0016 & 1.6422 & 0.3808\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  RMSE   Bias   RMSE_pct Bias_pct\n",
              "1 0.0067 0.0016 1.6422   0.3808  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.4** *Analyse the Tree location estimations*\n",
        "\n",
        "The last metric that will be analysed in this workshop is the tree location provided by 3DFin. We will measure the discrepance between the (x, y) reference coordinates of every tree *versus* the (x, y) coordinates provided by 3DFin.\n",
        "\n",
        "We will compute two discrepance metrics: the RMSE of the euclidean distance and the average euclidean distance. Note that we are dealing now with bidimensional data, which makes the calculations a bit different.\n",
        "\n",
        "We will start off from the euclidean distance ($d_E$) between reference ($\\text{ref}$) and detected ($\\text{det}$) tree location, which can be computed using the following formula:\n",
        "\n",
        "$d_E\\text{(ref, det)}=\\sqrt{(x_{ref}-x_{det})^2+(y_{ref}-y_{det})^2}$.\n",
        "\n",
        "It is important to notice that this metric is itself an error measurement. Its average coincides with the *Mean Average Error (MAE)*, a commonly used error measurement. It may be computed as follows:\n",
        "\n",
        "$\\bar{d_E}=\\text{MAE}=\\frac{1}{n}\\sum_{i=1}^{n}(d_{Ei})$.\n",
        "\n",
        "Finally, as we did previously, we can compute the RMSE, adapting the formula as follows:\n",
        "\n",
        "$\\text{RMSE}(d_E) = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(d_{Ei})^2}$,\n",
        "\n",
        "which may not be equal to the MAE in most cases.\n",
        "\n",
        "In the code cell below we call `compute_location_error` function to compute both metrics:"
      ],
      "metadata": {
        "id": "X-_FN6JJ92V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "location_results <- compute_location_error(matched_trees[, 2], matched_trees[, 3], matched_trees[, 5], matched_trees[, 6])\n",
        "location_results"
      ],
      "metadata": {
        "id": "2N8rOPJW94V7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "7d3c0ebd-b0d0-40c5-99ba-dbc58f10a438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 1 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>MAE</th><th scope=col>RMSE</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>0.1308</td><td>0.1464</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 1 × 2\n\n| MAE &lt;dbl&gt; | RMSE &lt;dbl&gt; |\n|---|---|\n| 0.1308 | 0.1464 |\n\n",
            "text/latex": "A data.frame: 1 × 2\n\\begin{tabular}{ll}\n MAE & RMSE\\\\\n <dbl> & <dbl>\\\\\n\\hline\n\t 0.1308 & 0.1464\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  MAE    RMSE  \n",
              "1 0.1308 0.1464"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}